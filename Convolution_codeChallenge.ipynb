{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGh0jVje7Clx0f36VSXBxf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avishek-astra/Deep_Learning_Experiments/blob/main/Convolution_codeChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kIl2qgEPc_Ne"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample** **problem**"
      ],
      "metadata": {
        "id": "qQvgKmswfGXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolve an image of size 1x256x256 to produce a 1x252x84 result"
      ],
      "metadata": {
        "id": "GcKjTG6EfQiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans  = 1 # RGB\n",
        "imsize   = [256,256]\n",
        "outChans = 1\n",
        "krnSize  = 7 # should be an odd number\n",
        "stride   = (1,3)\n",
        "padding  = 1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzTkRcctfDce",
        "outputId": "9829773f-cc42-40ea-b6a9-c0f42c8263af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [  1 252  84]\n",
            "Empirical size: [252, 84]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Real** **problems**"
      ],
      "metadata": {
        "id": "ROgIe5jmfpye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Convolve an image of size 3x64x64 to produce a 10x28x28 result"
      ],
      "metadata": {
        "id": "Zdf8tGmjfqKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans  = 3\n",
        "imsize   = [64,64]\n",
        "outChans =10\n",
        "krnSize  =39\n",
        "stride   = (1,1)\n",
        "padding  = 1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2ZLhWNsfFb0",
        "outputId": "21005038-1972-46a7-8e35-eb055bcc6461"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [10 28 28]\n",
            "Empirical size: [10, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2) Convolve an image of size 3x196x96 to produce a 5x66x49 result"
      ],
      "metadata": {
        "id": "gPGjS0sZHnRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "inChans  =3\n",
        "imsize   = [196,96]\n",
        "outChans = 5\n",
        "krnSize  =5\n",
        "stride   =(3,2)\n",
        "padding  =3\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR4BIvkvF4Zw",
        "outputId": "d1dffd36-cafb-4c67-f53f-db6c8dcd7858"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 5 66 49]\n",
            "Empirical size: [5, 66, 49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Convolve an image of size 1x32x32 to produce a 6x28x28 result"
      ],
      "metadata": {
        "id": "A73vd4PpJex5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note: these dimensions are the input -> first hidden layer of the famous LeNet-5\n",
        "\n",
        "# parameters\n",
        "inChans  =1\n",
        "imsize   =[32,32]\n",
        "outChans = 6\n",
        "krnSize  =7\n",
        "stride   =(1,1)\n",
        "padding  =1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13hq_RnyJZzS",
        "outputId": "9a471649-ec16-4f8a-f520-2b4b65cbc040"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 6 28 28]\n",
            "Empirical size: [6, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Convolve an image of size 3x227x227 to produce a 96x55x55 result"
      ],
      "metadata": {
        "id": "Phiko8ClJ_O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note: these dimensions are the input -> first hidden layer of the famous AlexNet\n",
        "\n",
        "# parameters\n",
        "inChans  =3\n",
        "imsize   =[227,227]\n",
        "outChans =96\n",
        "krnSize  =13\n",
        "stride   =(4,4)\n",
        "padding  =1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55F-4JI_J9Br",
        "outputId": "276aec5d-6984-4251-879c-b596a521cd56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [96 55 55]\n",
            "Empirical size: [96, 55, 55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Convolve an image of size 3x224x224 to produce a 64x224x224 result"
      ],
      "metadata": {
        "id": "rvqeJot1Kjqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note: these dimensions are the input -> first hidden layer of the famous VGG-16\n",
        "\n",
        "# parameters\n",
        "inChans  =3\n",
        "imsize   =[224,224]\n",
        "outChans = 64\n",
        "krnSize  = 1\n",
        "stride   =(1,1)\n",
        "padding  =1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhUtHY2nKeMc",
        "outputId": "f281f319-5ceb-460a-bd8c-153be9519918"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 64 226 226]\n",
            "Empirical size: [64, 226, 226]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOfqVhjwKxae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}